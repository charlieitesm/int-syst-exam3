{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# ITESM - MCC - Intelligent Systems\n",
        "## Exam 3 - Exercise 6\n",
        "\n",
        "### Carlos Eduardo Hernandez Rincon\n",
        "### Student ID: A01181616\n",
        "\n",
        "#### May 15th 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Instructions\n",
        "\n",
        "15p 6.- Given the data set “wineTestModel.csv”, construct a Jupyter notebook (kernel Python or R) to determine for each of its 6 instances the cultivar where they come from. For that, the “wine.csv” is provided which contain 172 records of 13\n",
        "chemical variables and a cultivar class. The chemical variables determine the cultivar where they come from.\n",
        "\n",
        "You will use Gaussian Naive Bayes procedure as shown in class. That is, you will use the Bayes’ Theorem and the Normal distribution of probabilities shown below.\n",
        "\n",
        "where π\u003d3.14159 ... and e\u003d2.71828\n",
        "\n",
        "It is prohibited utilize any library to compute the Gaussian Naive Bayes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Before running\n",
        "\n",
        "Make sure that your Jupyter can access the following libraries:\n",
        "1. numpy\u003d\u003d1.16.3\n",
        "2. pandas\u003d\u003d0.24.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-1-6c2cc89aad9e\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[1;32m----\u003e 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named \u0027pandas\u0027"
          ],
          "ename": "ModuleNotFoundError",
          "evalue": "No module named \u0027pandas\u0027",
          "output_type": "error"
        }
      ],
      "source": "import pandas as pd\nimport math"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "def calculate_normal_probability_distribution(mean: float, stdev: float, x: float):\n    pi \u003d 3.14159\n    euler \u003d 2.71828\n\n    first_part \u003d 1 / (stdev * math.sqrt((2 * pi)))\n\n    euler_power \u003d -0.5 * math.pow((x - mean) / stdev, 2)\n    second_part \u003d math.pow(euler, euler_power)\n\n    probability \u003d first_part * second_part\n\n    return probability\n\n\ndef calculate_gaussian_naive_bayes(features_posteriors: list, label_posterior: float):\n    posterior \u003d 1\n\n    # Multiply all of the features posteriors to in order to calculate Naive Bayes\n    for fp in features_posteriors:\n        posterior *\u003d fp\n\n    posterior \u003d posterior * label_posterior\n\n    return posterior",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "male_fp \u003d [\n    calculate_normal_probability_distribution(5.855, 0.187171935, 6),\n    calculate_normal_probability_distribution(176.25, 11.08677891, 130),\n    calculate_normal_probability_distribution(11.25, 0.957427108, 8)\n]\n\nposterior_male \u003d calculate_gaussian_naive_bayes(male_fp, 0.5)\n\nfemale_fp \u003d [\n    calculate_normal_probability_distribution(5.4175, 0.311809237, 6),\n    calculate_normal_probability_distribution(132.5, 23.62907813, 130),\n    calculate_normal_probability_distribution(7.5, 1.290994449, 8)\n]\n\nposterior_female \u003d calculate_gaussian_naive_bayes(female_fp, 0.5)\n\n# Read the training dataset\ndata \u003d pd.read_csv(\"../Jupyter/wine.csv\", skipinitialspace\u003dTrue, skip_blank_lines\u003dTrue)\n\ndata.sort_values(\"cultivar\", inplace\u003dTrue)\n\nwine_possible_labels \u003d data[\"cultivar\"].unique()\n\nlabel_1 \u003d data.loc[data[\u0027cultivar\u0027] \u003d\u003d 1].drop(\"cultivar\", axis\u003d1)\nlabel_2 \u003d data.loc[data[\u0027cultivar\u0027] \u003d\u003d 2].drop(\"cultivar\", axis\u003d1)\nlabel_3 \u003d data.loc[data[\u0027cultivar\u0027] \u003d\u003d 3].drop(\"cultivar\", axis\u003d1)\n\nlabel_1_means \u003d label_1.mean(axis\u003d0)\nlabel_2_means \u003d label_2.mean(axis\u003d0)\nlabel_3_means \u003d label_3.mean(axis\u003d0)\n\n# We pass ddof to calculate the Population Std Dev, by default Pandas uses a ddof\u003d1 which is for the Sample Std Dev\nlabel_1_stdev \u003d label_1.std(axis\u003d0, ddof\u003d0)\nlabel_2_stdev \u003d label_2.std(axis\u003d0, ddof\u003d0)\nlabel_3_stdev \u003d label_3.std(axis\u003d0, ddof\u003d0)\n\n# Read the test dataset\ntest_data \u003d pd.read_csv(\"../Jupyter/wineTestModel.csv\", skipinitialspace\u003dTrue, skip_blank_lines\u003dTrue)\n\n# Drop the cultivar label as this is the one we will calculate\ntest_data.drop(\"cultivar\", axis\u003d1, inplace\u003dTrue)\n\n# Prepare the variables that we\u0027ll use for the calculation and drop the cultivar label\nfeature_list \u003d list(test_data.columns.values)\n\n# The posteriors, that is P(label_1), is equal to the number of cultivar\u003d\u003d1, 2 or 3 divided by the total num of records\nposterior_1 \u003d len(label_1) / len(data)\nposterior_2 \u003d len(label_2) / len(data)\nposterior_3 \u003d len(label_3) / len(data)\n\n# We\u0027ll add all of the information in symmetric lists in order to ease the calculation loop structure\ncultivar_label_posteriors \u003d [posterior_1, posterior_2, posterior_3]\nmeans \u003d [label_1_means, label_2_means, label_3_means]\nstdevs \u003d [label_1_stdev, label_2_stdev, label_3_stdev]\n\ndetermined_labels \u003d []\n\n# Begin the calculation\nfor row_index, row in test_data.iterrows():\n    print(\"\\n\\n***************************\")\n    print(f\"Calculating label for row {row_index + 1}...\")\n    print(\"***************************\\n\")\n\n    cultivar_label_bayes_probabilities \u003d []\n\n    # Check each of the labels\n    for label_idx in range(3):\n\n        print(f\"\\n-------Calculating P(cultivar \u003d\u003d {label_idx + 1})...\\n\")\n\n        features_gauss \u003d []\n\n        for feature in feature_list:\n            feature_x \u003d row[feature]\n            feature_mean \u003d means[label_idx][feature]\n            feature_stdev \u003d stdevs[label_idx][feature]\n\n            feature_gauss \u003d calculate_normal_probability_distribution(mean\u003dfeature_mean,\n                                                                      stdev\u003dfeature_stdev,\n                                                                      x\u003dfeature_x)\n\n            features_gauss.append(feature_gauss)\n\n            print(f\"-------Feature: {feature} -------\")\n            print(f\"X \u003d {feature_x}\")\n            print(f\"Feature mean \u003d {feature_mean}\")\n            print(f\"Feature Std Dev \u003d {feature_stdev}\")\n            print(f\"P({feature}| Cultivar \u003d\u003d {label_idx +1}) \u003d {feature_gauss}\")\n\n        # Calculate the posterior of the label given all of the features P(\n        cultivar_posterior \u003d cultivar_label_posteriors[label_idx]\n\n        label_probability \u003d calculate_gaussian_naive_bayes(features_gauss, cultivar_posterior)\n\n        cultivar_label_bayes_probabilities.append(label_probability)\n\n        print(f\"\\n \u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e P(cultivar \u003d\u003d {label_idx + 1} | {\u0027,\u0027.join(feature_list)}): {label_probability}\")\n\n    # To get the final value, we just get the index in the label probabilities and offset the value by 1\n    final_cultivar \u003d cultivar_label_bayes_probabilities.index(max(cultivar_label_bayes_probabilities)) + 1\n    determined_labels.append(final_cultivar)\n\n    print(f\"\\n \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d RESULTS FOR ROW {row_index + 1} \u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\")\n    print(\"Given the following Bayes posteriors for each label:\")\n\n    for result_idx, result in enumerate(cultivar_label_bayes_probabilities):\n        print(f\"P(cultivar \u003d\u003d {result_idx + 1}): {result}\")\n\n    print(f\"ROW {row_index + 1} is probably Cultivar {final_cultivar}\")\n\n# Adjust the DataFrame to the determined cultivar label\ntest_data.insert(loc\u003d0, column\u003d\u0027cultivar\u0027, value\u003ddetermined_labels)\n\nprint(\"Final Test Dataset:\")\nprint(test_data.to_string())\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "int-syst-exam3-venv",
      "language": "python",
      "name": "int-syst-exam3-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}